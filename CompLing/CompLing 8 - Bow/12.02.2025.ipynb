{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Всякие импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import razdel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('labeled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def razdel_tokenizer(text):\n",
    "    return [token.text for token in razdel.tokenize(text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Встроенная"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=10, max_features=100, max_df=0.3)\n",
    "X = vectorizer.fit_transform(train.comment)\n",
    "X_test = vectorizer.transform(test.comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.toxic.values\n",
    "y_test = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB(alpha=1.)\n",
    "clf.fit(X, y)\n",
    "preds = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Кастомная"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jingni\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "my_vectorizer = TfidfVectorizer(tokenizer=razdel_tokenizer)\n",
    "X_custom = my_vectorizer.fit_transform(train.comment)\n",
    "X_test_custom = my_vectorizer.transform(test.comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_custom = train.toxic.values\n",
    "y_test_custom = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MultinomialNB(alpha=1.)\n",
    "my_clf.fit(X_custom, y_custom)\n",
    "preds_custom = my_clf.predict(X_test_custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Сравнение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.97      0.84       999\n",
      "         1.0       0.79      0.23      0.36       443\n",
      "\n",
      "    accuracy                           0.75      1442\n",
      "   macro avg       0.77      0.60      0.60      1442\n",
      "weighted avg       0.76      0.75      0.69      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.99      0.85       999\n",
      "         1.0       0.93      0.23      0.37       443\n",
      "\n",
      "    accuracy                           0.76      1442\n",
      "   macro avg       0.84      0.61      0.61      1442\n",
      "weighted avg       0.80      0.76      0.70      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_custom, preds_custom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7461858529819695\n",
      "Accuracy customized: 0.7593619972260749\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
    "print(\"Accuracy customized:\", accuracy_score(y_test_custom, preds_custom))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Встроенная"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X = vectorizer.fit_transform(train.comment)\n",
    "X_test = vectorizer.transform(test.comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.toxic.values\n",
    "y_test = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB(alpha=1.)\n",
    "clf.fit(X, y)\n",
    "preds = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Кастомная токенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jingni\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "my_vectorizer = CountVectorizer(tokenizer=razdel_tokenizer)\n",
    "X_custom = my_vectorizer.fit_transform(train.comment)\n",
    "X_test_custom = my_vectorizer.transform(test.comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_custom = train.toxic.values\n",
    "y_test_custom = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MultinomialNB()\n",
    "my_clf.fit(X_custom, y_custom)\n",
    "y_pred_custom = my_clf.predict(X_test_custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Сравнение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.96      0.91       999\n",
      "         1.0       0.88      0.67      0.76       443\n",
      "\n",
      "    accuracy                           0.87      1442\n",
      "   macro avg       0.87      0.81      0.83      1442\n",
      "weighted avg       0.87      0.87      0.86      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.99      0.85       999\n",
      "         1.0       0.93      0.23      0.37       443\n",
      "\n",
      "    accuracy                           0.76      1442\n",
      "   macro avg       0.84      0.61      0.61      1442\n",
      "weighted avg       0.80      0.76      0.70      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_custom, preds_custom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8682385575589459\n",
      "Accuracy customized: 0.7593619972260749\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
    "print(\"Accuracy customized:\", accuracy_score(y_test_custom, preds_custom))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для векторайзера Tf-Idf лучше сработала кастомная токенизация, хотя разница между встроенной невелика.  \n",
    "Для векторайзера Count сильно лучше сработала встроенная токенизация.  \n",
    "Почти у всех низкий recall, но у встроенного CountVectorizer аж целых 0.64, что и значительно повлияло на общую точность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2 BeamSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf-idf - LogisticRegression\n",
    "count - decisiontree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_count = CountVectorizer(max_features=100, ngram_range=(1, 2), strip_accents='unicode',min_df=10, max_df = 0.3 )\n",
    "\n",
    "X_count = vectorizer_count.fit_transform(train.comment)\n",
    "X_test_count = vectorizer_count.transform(test.comment)\n",
    "y_count = train.toxic.values\n",
    "y_test_count = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_tf= TfidfVectorizer(min_df=10, max_features=100, max_df=0.3, ngram_range=(1, 2), smooth_idf=True)\n",
    "X_tf = vectorizer_tf.fit_transform(train.comment)\n",
    "X_test_tf = vectorizer_tf.transform(test.comment)\n",
    "y_tf = train.toxic.values\n",
    "y_test_tf = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.64      0.73       999\n",
      "         1.0       0.48      0.75      0.59       443\n",
      "\n",
      "    accuracy                           0.68      1442\n",
      "   macro avg       0.67      0.70      0.66      1442\n",
      "weighted avg       0.74      0.68      0.69      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_log =  LogisticRegression(C=0.1, class_weight='balanced', solver='saga')\n",
    "clf_log.fit(X_count, y_count)\n",
    "preds_log = clf_log.predict(X_test_count)\n",
    "\n",
    "print(classification_report(y_test_count, preds_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jingni\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\neighbors\\_base.py:598: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.79      0.79       999\n",
      "         1.0       0.53      0.53      0.53       443\n",
      "\n",
      "    accuracy                           0.71      1442\n",
      "   macro avg       0.66      0.66      0.66      1442\n",
      "weighted avg       0.71      0.71      0.71      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_knei = KNeighborsClassifier(n_neighbors=15, algorithm='ball_tree', leaf_size=10)\n",
    "clf_knei.fit(X_tf, y_tf)\n",
    "preds_tf = clf_knei.predict(X_test_tf)\n",
    "\n",
    "print(classification_report(y_test_tf, preds_tf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я потыкала разные параметры у разных классификаторов, но лучшее значение f1-меры это 0.69 :((("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Топ 10 CountVectorizer LogisticRegression:\n",
      "Нет, мне тебя жалко, ты ненавидишь союз, не любишь русских, особенно Путина, даже своих предков также поливаеш грязью, особенно символично, что несмотря на ненависть к русским, у тебя такой ник, это какая-то квинтэссенция изливания желчи во всё вокруг. Ведь по сути, ты же просто пришёл и сказал: вот это говно, это и это, когда к тебе обратились (понятно, что именно ради этого всё и затевалось) со словами, молодой человек, ваш юношеский максимализм неуместен, вы посчитали это слабостью: как же, они не могут так же издеваться и при этом не попасть под бан.\n",
      "\n",
      "Оп. Доказательство того, что ты не умеешь читать. Вижу, что такое заусенец, вижу кромки деталей не должны иметь заусенцев . Только я, в отличии от тебя, еще читаю другие слова кроме искомых, а именно: кромки МЕТАЛЛИЧЕСКИХ деталей не должны иметь заусенцев . Ты слился: по IQ, по умению читать, по умению делать оценку качества, по умению отвечать на вопросы. Странно, что ты дышать умеешь и даже писать.\n",
      "\n",
      "именно так. смотрю на тебя, стаса, вестника дури и считаю ебланами. Твоё дело. Это вполне логичная реакция буржуя на тот факт, что его собрались раскулачивать. мотрю на всех царей(!) ссср и считаю ебланами, в том числе их ебланскую жадность, жестокость и жажду власти. А вот тут ты запизделся. СССР сделал из России сверхгосударство в сильнейшим образованием, мощнейшей экономикой, огромной военной мощью и кучей инновационных технологий. Можно сколько угодно рассуждать про мораль и этику, но нельзя отрицать статистику. С ней нельзя спорить. Что мы имеем? Продолжительность жизни - выросла в 2 раза. Образование - с 10 до 90 населения. Прирост населения - 40кк. Уровень жизни - растёт. Электрификация - всего государства. Нельзя спорить с цифрами. Посмотри на картинки. Это действительно итог работы тиранов и царе? Это итог работы душегубов и руссофобов? Или же что, статистику подменили и в РИ люди не были голодными, холодными, необразованными и без света? Может в РИ технологии какие изобретали, а? тебя ктото угнетает? Капиталисты. Все и сразу. Всё просто. сори, но ты просто тупой. все нынешние коммунисты просто ебаные страусы, если я засунул голову в песок и не вижу фактов - это значит, что их нет Каких фактов. Вот у меня на картинках статистические факты. Ты мне говоришь про голод и репрессии, а я говорю тебе что срок жизни человека вырос с 30 лет до 70, а население выросло с 170кк до 214кк. Где репрессии? Где голод? Почему они противоречат статистике? растрелянных не было Было. Но мало и по делу. А что? Нельзя расстреливать преступников? Почему? не понравился коммуняке - ты недочеловек, расстрелять. Не хочу тебя расстраивать, но коммунизм это диктатура пролетариата. То есть решение о расстреле принимает не один человек, а всё государство, просто подписывает его ответственный. А если ты не нравишься целому государству - чтож, сам виноват, наверняка творил хуйню. Я вот хуйню бы творить не стал и если надо, то изменился бы ради общественного блага. Поэтому бы меня не расстреляли, я же не преступник как те кого расстреляли в СССР. то, что дяди в интернете с псевдофактами сказали, что коммунисты были святыми Никто не говорит что они были святыми. Более того - на всех каналах что я посоветовал во многом критикуют СССР. Проблема в том, что критика СССР из вне, то есть не из стана левых сил, всегда сводится к мемам уровня Катыни и Голодомора, которые являются чистейшей ложью и клеветой на весь левый корпус. почитай про пакт молотова-рибентропа Было такое, да. Тут всё дело было в том, что в глазах коммуниста разницы между буржуем нацистом и буржуем империалистом - нет. Поэтому ожидания коммунистов были что вся грязь себя перехуярит и мы восстановим их государства под коммунистическим флагом. Го Хитлур был ебанутым и решил воевать со всем миром. захват польши Не существует такого факта как ЗАХВАТ в мире коммунизма. Коммунизм подразумевает интернационал и мировое государство. Нельзя захватить чужую территорию потому, что все территории принадлежат коммунизму. катынь Это мем и фейк. Поляки хуярили своих же в погоне за властью. массовое переселение целых народов внутри страны Что плохого в распределение производственных сил? Это банальная оптимизация. гулаг Что плохого в тюрьмах для преступников в отдалении? для тебя и твоих кумиров только одна проблема в нынешнем мире Наверно поэтому с каждым годом коммунистов всё больше и больше, а так же реальной оппозицией которая борется за права людей в России являются коммунисты, да? смешно то, что каждый из вас адептов коммунизма ерзает на капиталистическом кукане, приговаривая какие у меня охуенные идеи есть для этого кукана, вот бы он был красным . Компьютеры теперь капиталистическая идея, лол? Щта? Ты вообще там поехал чтоли? Еще раз - коммунизм это не сидеть в тёмном сыром подвале и жрать говяжий анус, коммунизм это прогресс и справедливость. Первые ЭВМ были изобретены в СССР. СССР сделал огромный вклад в развитие ЭВМ технологий и изобрёл гениальную троичную логику. СССР делал канкуляторы и телевизеры, делал радивы и телефоны. Ты совсем там ебобо? Речь коммуниста была про то что нехуй в игрушки играть, а пора использовать ЭВМ для работы, не более. ты в упор не видишь, хуле тебе объяснять Не вижу. Скинь шебмки.\n",
      "В role reversal треде fet поселился шизик, портящий всем живущим там картину. Последние несколько тредов он занимается такими вещами, как: - Пропагандой откровенно фашистских, нацистких и националистких идей: сравнивает русскую нацию со свиньями, синюшниками, нелюдями и многими другими нелицеприятными эпитетами. Признаёт величие одной нации над другой. На лицо 282. - Форсом камвхоры дельфинихи , прикрепляя её фотографии к своим сообщениям. Данная камвхора никакого отношения к тематике треда не имеет. - Аватаркоблядством: прикрепляет к своим сообщениям совершенно нетематические арты по MLP, фото вышеуказанной кавхоры. - Постингом боевых картиночек с копированием поста собеседника и написания его гринтекстом. - Признанием того, что он обходит выданные ему баны, использует прокси и смену IP - адреса. - Постит откровенно провокационные посты, разжигает срачи, флеймит, признаёт что постит провокации. - Занимается повсеместным оскорблением участников треда, вешает на них ярлыки, относится ко всем неуважительно. - Форсит неревелантные треду фетиши, такие например, как куколд - фетиш, мужской гомосексуализм. - Постингом оффтопа. - Искажает суть треда и самого фетиша в корне, относится с издёвкой к представителям сего фетиша, указывает им на их якобы недостатки. - Постит в тред откровенно фейковые анкеты, тем самым организуя набеги на личностей, которые о треде слышать не слышали. - Повсеместным вниманиеблядством. - Семенит ответами к своим постам, с якобы одобрением, хотя любой здравомыслящий человек в жизни с высказываниями этого одарённого не согласится. - Все неудобные ответы к своим постам игнорирует, в обсуждении часто переходит на личности, отступая от сути самого обсуждения. - Называет посетителей треда пикабушниками . - Обходит спам - лист. - Неуважительно относится к девушкам, именуя их например селёдками . Всё это только за этот тред, а постит он уже тредов примерно пять. Также возможно он прибежит в этот тред, предупреждаю заранее, к этому надо быть готовым. Моча, вытащи голову из жопы и займись своей работой.\n",
      "\n",
      "ой блять, как же вы заебали один еблан впишется в тему и прилично устроится и всё!1 - ОН, БЛЯТЬ, ВС СДЕЛАЛ САМ!1 И ВСЕГО ДОБИЛСЯ САМ!1 не по стечению обстоятельств, не потому что попёрло, а потому что ОН ВЕЛИКИЙ САМ!1 и тут же другие васи, которым чуть меньше в жизни подогнали и чуть хуже устроили, начинают ему подпевать - ВОТ СМОТРИТЕ! ОН САМ ВСЕГО ДОБИЛСЯ!1 ссука, какие же вы имбецилы... вы даже из мамкиной утробы сами хер появились, фанаты Золушки, блять\n",
      "\n",
      "Какую ещё нахуй правоту ? Ты сказал, что правый и за мораль и всё такое, я тебе предъявил мол есть ли у тебя семья жена. Ты начал маняврировать, что то про кукан. Где я слился то, питушок ?\n",
      "\n",
      "х новостях ни разу - НИ РАЗУ не было такого, чтобы пиздюки не напиздели с три короба в свою поль Ты тупенький? тебе даже видео показали, а ты оправдываешь нападавшего.\n",
      "\n",
      "Какой символизм! Колючая проволока как последний заслон здравого смысла. Брёвна как первые шаги к пагубной привычке. Вращающее бревно как собственно сигарета. Пламя с двух сторон символизирующее, что пока горит сигарета с одной стороны ты сжигаешь себя с другой. Акулы как символ рака лёгких поджидающий тебя на твоём пути курильщика. Срочно в музей этот шедевр! Gifx\n",
      "\n",
      "Господи, ты просто как конченый все отрицаешь. Тебя тыкаешь в факты, а тебе просто похер. Кому не поебать на твоё мнение, если люди пишут, что проблемы остались.\n",
      "\n",
      "ути пути твоя подруга у тебя в штанах видит, но разве мне это тебе говорить? ты и сам это прекрасно знаешь\n",
      "\n",
      "\n",
      "Топ 10 TfidfVectorizer KNeighborsClassifier:\n",
      "Скажи ему внезапно что у тебя туберкулёз.\n",
      "\n",
      "Бля я не за таким сюда першол. Ты че тут наванговал? Срочно бегу принимать таблэтку. Да я ебал сюда ходить.\n",
      "\n",
      "Ага, ебёшься с девушкой, а вокруг тебя ещё куча людей ебётся\n",
      "Ненужный кусок говна лезет во все щели. E nt,z bpj hnf7 у тебя изо рта?\n",
      "\n",
      "Чувак у тебя диагноз. Отойди от монитора и успокойся. Ложись в кровать и попробуй заснуть.\n",
      "\n",
      "Другого я от тебя и не ждал, школьник максималист.\n",
      "\n",
      "Двачую тебя, анончик. Олечка просто идеал женщины.\n",
      "\n",
      "Что она у тебя такая жирная? На шаверму её готовишь?\n",
      "\n",
      "Предлагаю пять тыщь и ебу тебя в жопу на стриме\n",
      "\n",
      "Ствол хуже, потому что пока ты поднимешь, снимешь с предохранителя итд ты уже труп. С 2 метров боец с ножом успевает нанести удар неготовому противнику, вооружённому пистолетом прежде чем тот начнёт стрелять. Большим холодным оружием можно отмахнуться намного быстрее, да и оппонент другую тактику изберёт. Время на основании видоса из ютуба,где 2 инструктора по стрельбе и бою на ножах решили проверить, насколько реально от внезапного нападения с пестом отбиться.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_top(clf, vec, X_test):\n",
    "    probas = clf.predict_proba(vec.transform(X_test))[:, 1]\n",
    "    top = probas.argsort()[-10:][::-1]\n",
    "    return X_test.iloc[top]\n",
    "\n",
    "top1 = get_top(clf_log, vectorizer_count, test.comment)\n",
    "top2 = get_top(clf_knei, vectorizer_tf , test.comment)\n",
    "\n",
    "\n",
    "print(\"\\nТоп 10 CountVectorizer LogisticRegression:\")\n",
    "for i in top1:\n",
    "    print(i)\n",
    "\n",
    "print(\"\\nТоп 10 TfidfVectorizer KNeighborsClassifier:\")\n",
    "for i in top2:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У комбинации CountVectorizer LogisticRegression и более токсичные, а агрессивные комментарии... И они сильно длиннее. (точных совпадений нет)  \n",
    "У комбинации TfidfVectorizer KNeighborsClassifier есть не такие обидные комментарии и скорее в одном комментарии только одно оскорбление.  \n",
    "Наверное потому что просто векторайзеры по-разному работают вот.\n",
    "\n",
    "Люблю Твиттер. То есть Х. (нет.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
